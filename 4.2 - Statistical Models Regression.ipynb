{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "improved-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from numpy.random import seed\n",
    "\n",
    "from keras.layers.experimental import preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "impaired-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = './Data/output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-lover",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "specified-revolution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PSGC_BRGY</th>\n",
       "      <th>both_age_0_to_4</th>\n",
       "      <th>male_age_0_to_4</th>\n",
       "      <th>female_age_0_to_4</th>\n",
       "      <th>both_age_5_to_9</th>\n",
       "      <th>male_age_5_to_9</th>\n",
       "      <th>female_age_5_to_9</th>\n",
       "      <th>both_age_10_to_14</th>\n",
       "      <th>male_age_10_to_14</th>\n",
       "      <th>female_age_10_to_14</th>\n",
       "      <th>...</th>\n",
       "      <th>SDG_Type_Worker_Pro</th>\n",
       "      <th>SDG_Type_Worker_Tec</th>\n",
       "      <th>SDG_Type_Worker_Cle</th>\n",
       "      <th>SDG_Type_Worker_Ser</th>\n",
       "      <th>SDG_Type_Worker_Ski</th>\n",
       "      <th>SDG_Type_Worker_Cra</th>\n",
       "      <th>SDG_Type_Worker_Pla</th>\n",
       "      <th>SDG_Type_Worker_Ele</th>\n",
       "      <th>SDG_Type_Worker_Arm</th>\n",
       "      <th>SDG_less_than_54_sqft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PH150702001</td>\n",
       "      <td>88.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042654</td>\n",
       "      <td>0.014218</td>\n",
       "      <td>0.085308</td>\n",
       "      <td>0.208531</td>\n",
       "      <td>0.507109</td>\n",
       "      <td>0.033175</td>\n",
       "      <td>0.014218</td>\n",
       "      <td>0.052133</td>\n",
       "      <td>0.023697</td>\n",
       "      <td>0.275449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PH150702002</td>\n",
       "      <td>210.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.002976</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.529762</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.113095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PH150702005</td>\n",
       "      <td>277.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051637</td>\n",
       "      <td>0.021411</td>\n",
       "      <td>0.040302</td>\n",
       "      <td>0.070529</td>\n",
       "      <td>0.488665</td>\n",
       "      <td>0.032746</td>\n",
       "      <td>0.059194</td>\n",
       "      <td>0.164987</td>\n",
       "      <td>0.011335</td>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PH150702006</td>\n",
       "      <td>352.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016966</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.023952</td>\n",
       "      <td>0.106786</td>\n",
       "      <td>0.525948</td>\n",
       "      <td>0.019960</td>\n",
       "      <td>0.048902</td>\n",
       "      <td>0.171657</td>\n",
       "      <td>0.004990</td>\n",
       "      <td>0.061657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PH150702007</td>\n",
       "      <td>270.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.011696</td>\n",
       "      <td>0.023392</td>\n",
       "      <td>0.084795</td>\n",
       "      <td>0.494152</td>\n",
       "      <td>0.081871</td>\n",
       "      <td>0.125731</td>\n",
       "      <td>0.096491</td>\n",
       "      <td>0.010234</td>\n",
       "      <td>0.391509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PSGC_BRGY  both_age_0_to_4  male_age_0_to_4  female_age_0_to_4  \\\n",
       "0  PH150702001             88.0             54.0               34.0   \n",
       "1  PH150702002            210.0            100.0              110.0   \n",
       "3  PH150702005            277.0            152.0              125.0   \n",
       "4  PH150702006            352.0            146.0              206.0   \n",
       "5  PH150702007            270.0            140.0              130.0   \n",
       "\n",
       "   both_age_5_to_9  male_age_5_to_9  female_age_5_to_9  both_age_10_to_14  \\\n",
       "0             79.0             35.0               44.0               73.0   \n",
       "1            161.0             77.0               84.0              133.0   \n",
       "3            305.0            159.0              146.0              269.0   \n",
       "4            354.0            201.0              153.0              398.0   \n",
       "5            236.0            114.0              122.0              220.0   \n",
       "\n",
       "   male_age_10_to_14  female_age_10_to_14  ...  SDG_Type_Worker_Pro  \\\n",
       "0               42.0                 31.0  ...             0.042654   \n",
       "1               69.0                 64.0  ...             0.047619   \n",
       "3              155.0                114.0  ...             0.051637   \n",
       "4              217.0                181.0  ...             0.016966   \n",
       "5              121.0                 99.0  ...             0.026316   \n",
       "\n",
       "   SDG_Type_Worker_Tec  SDG_Type_Worker_Cle  SDG_Type_Worker_Ser  \\\n",
       "0             0.014218             0.085308             0.208531   \n",
       "1             0.002976             0.011905             0.047619   \n",
       "3             0.021411             0.040302             0.070529   \n",
       "4             0.002994             0.023952             0.106786   \n",
       "5             0.011696             0.023392             0.084795   \n",
       "\n",
       "   SDG_Type_Worker_Ski  SDG_Type_Worker_Cra  SDG_Type_Worker_Pla  \\\n",
       "0             0.507109             0.033175             0.014218   \n",
       "1             0.529762             0.053571             0.119048   \n",
       "3             0.488665             0.032746             0.059194   \n",
       "4             0.525948             0.019960             0.048902   \n",
       "5             0.494152             0.081871             0.125731   \n",
       "\n",
       "   SDG_Type_Worker_Ele  SDG_Type_Worker_Arm  SDG_less_than_54_sqft  \n",
       "0             0.052133             0.023697               0.275449  \n",
       "1             0.113095             0.000000               0.287554  \n",
       "3             0.164987             0.011335               0.002092  \n",
       "4             0.171657             0.004990               0.061657  \n",
       "5             0.096491             0.010234               0.391509  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(OUTPUT_PATH + 'Population_Schools_SDGs_Clean.csv')\n",
    "dataset = dataset.dropna()\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-hawaiian",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "technical-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "SDG = dataset.iloc[:,84:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-stewart",
   "metadata": {},
   "source": [
    "#### 1. Elementary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "threatened-chair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1529"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_elem = SDG.copy()\n",
    "data_elem['NUM_SCHOOLS'] = dataset['SCH_CAT_CES'] + dataset['SCH_CAT_ES'] + dataset['SCH_CAT_PS'] + dataset['SCH_CAT_PES']\n",
    "data_elem['ELEM_POPN'] = dataset['both_age_6_to_12']\n",
    "len(data_elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-domestic",
   "metadata": {},
   "source": [
    "#### 2. High School"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "verified-liberty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1529"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hs = SDG.copy()\n",
    "data_hs['NUM_SCHOOLS'] = dataset['SCH_CAT_JHS'] + dataset['SCH_CAT_SHS'] + dataset['SCH_CAT_PJHS'] + dataset['SCH_CAT_PSHS']\n",
    "data_hs['HS_POPN'] = dataset['both_age_13_to_16']\n",
    "len(data_hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "operational-flash",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, testing_data = train_test_split(data_elem, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "federal-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_data.drop(['NUM_SCHOOLS'], axis=1)\n",
    "y_train = training_data['NUM_SCHOOLS']\n",
    "\n",
    "X_test = testing_data.drop(['NUM_SCHOOLS'], axis=1)\n",
    "y_test = testing_data['NUM_SCHOOLS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "tight-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = preprocessing.Normalization()\n",
    "normalizer.adapt(np.array(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "theoretical-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model():\n",
    "    model = Sequential()\n",
    "    model.add(normalizer)\n",
    "    model.add(Dense(4, input_dim=2, activation='relu'))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "#     model.add(Dense(20, activation='tanh', input_dim=5, kernel_initializer='uniform'))\n",
    "#     model.add(Dense(1, activation='linear', kernel_initializer='uniform'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "color-christianity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 2.8369 - val_loss: 2.1154\n",
      "Epoch 2/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.9908 - val_loss: 1.4361\n",
      "Epoch 3/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1.3058 - val_loss: 1.0163\n",
      "Epoch 4/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1.2710 - val_loss: 0.8482\n",
      "Epoch 5/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.8748 - val_loss: 0.7620\n",
      "Epoch 6/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.8328 - val_loss: 0.7045\n",
      "Epoch 7/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.8533 - val_loss: 0.6557\n",
      "Epoch 8/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.8948 - val_loss: 0.6218\n",
      "Epoch 9/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.8023 - val_loss: 0.5943\n",
      "Epoch 10/200\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.7730 - val_loss: 0.5779\n",
      "Epoch 11/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7602 - val_loss: 0.5672\n",
      "Epoch 12/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7171 - val_loss: 0.5632\n",
      "Epoch 13/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8981 - val_loss: 0.5575\n",
      "Epoch 14/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5772 - val_loss: 0.5516\n",
      "Epoch 15/200\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.6330 - val_loss: 0.5483\n",
      "Epoch 16/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4687 - val_loss: 0.5447\n",
      "Epoch 17/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8799 - val_loss: 0.5459\n",
      "Epoch 18/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6550 - val_loss: 0.5396\n",
      "Epoch 19/200\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 1.0421 - val_loss: 0.5400\n",
      "Epoch 20/200\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 1.0167 - val_loss: 0.5426\n",
      "Epoch 21/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8155 - val_loss: 0.5387\n",
      "Epoch 22/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.6246 - val_loss: 0.5346\n",
      "Epoch 23/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7756 - val_loss: 0.5382\n",
      "Epoch 24/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5859 - val_loss: 0.5336\n",
      "Epoch 25/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8576 - val_loss: 0.5337\n",
      "Epoch 26/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7557 - val_loss: 0.5343\n",
      "Epoch 27/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7483 - val_loss: 0.5325\n",
      "Epoch 28/200\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.7465 - val_loss: 0.5300\n",
      "Epoch 29/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8135 - val_loss: 0.5331\n",
      "Epoch 30/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5113 - val_loss: 0.5276\n",
      "Epoch 31/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8368 - val_loss: 0.5258\n",
      "Epoch 32/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7653 - val_loss: 0.5232\n",
      "Epoch 33/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6752 - val_loss: 0.5258\n",
      "Epoch 34/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.0355 - val_loss: 0.5231\n",
      "Epoch 35/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5257 - val_loss: 0.5194\n",
      "Epoch 36/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7366 - val_loss: 0.5177\n",
      "Epoch 37/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8276 - val_loss: 0.5112\n",
      "Epoch 38/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.7721 - val_loss: 0.5088\n",
      "Epoch 39/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5625 - val_loss: 0.5044\n",
      "Epoch 40/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.9140 - val_loss: 0.5122\n",
      "Epoch 41/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5660 - val_loss: 0.5104\n",
      "Epoch 42/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6871 - val_loss: 0.5149\n",
      "Epoch 43/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8880 - val_loss: 0.5166\n",
      "Epoch 44/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.8348 - val_loss: 0.5133\n",
      "Epoch 45/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5565 - val_loss: 0.5115\n",
      "Epoch 46/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6643 - val_loss: 0.5130\n",
      "Epoch 47/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5377 - val_loss: 0.5100\n",
      "Epoch 48/200\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.6036 - val_loss: 0.5166\n",
      "Epoch 49/200\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.6779 - val_loss: 0.5177\n",
      "Epoch 50/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8980 - val_loss: 0.5234\n",
      "Epoch 51/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5583 - val_loss: 0.5130\n",
      "Epoch 52/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5438 - val_loss: 0.5160\n",
      "Epoch 53/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6767 - val_loss: 0.5228\n",
      "Epoch 54/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6391 - val_loss: 0.5274\n",
      "Epoch 55/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5359 - val_loss: 0.5184\n",
      "Epoch 56/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.6412 - val_loss: 0.5247\n",
      "Epoch 57/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6216 - val_loss: 0.5257\n",
      "Epoch 58/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5745 - val_loss: 0.5287\n",
      "Epoch 59/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7455 - val_loss: 0.5332\n",
      "Epoch 60/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5622 - val_loss: 0.5199\n",
      "Epoch 61/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6502 - val_loss: 0.5287\n",
      "Epoch 62/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6329 - val_loss: 0.5230\n",
      "Epoch 63/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4972 - val_loss: 0.5314\n",
      "Epoch 64/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6582 - val_loss: 0.5350\n",
      "Epoch 65/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6444 - val_loss: 0.5250\n",
      "Epoch 66/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5324 - val_loss: 0.5301\n",
      "Epoch 67/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5655 - val_loss: 0.5307\n",
      "Epoch 68/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5566 - val_loss: 0.5331\n",
      "Epoch 69/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4725 - val_loss: 0.5326\n",
      "Epoch 70/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6239 - val_loss: 0.5302\n",
      "Epoch 71/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5420 - val_loss: 0.5267\n",
      "Epoch 72/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4969 - val_loss: 0.5365\n",
      "Epoch 73/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5794 - val_loss: 0.5335\n",
      "Epoch 74/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7037 - val_loss: 0.5354\n",
      "Epoch 75/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5191 - val_loss: 0.5325\n",
      "Epoch 76/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4467 - val_loss: 0.5373\n",
      "Epoch 77/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4548 - val_loss: 0.5332\n",
      "Epoch 78/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5010 - val_loss: 0.5425\n",
      "Epoch 79/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5714 - val_loss: 0.5447\n",
      "Epoch 80/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5307 - val_loss: 0.5384\n",
      "Epoch 81/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6315 - val_loss: 0.5453\n",
      "Epoch 82/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5419 - val_loss: 0.5406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5286 - val_loss: 0.5395\n",
      "Epoch 84/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6258 - val_loss: 0.5504\n",
      "Epoch 85/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4859 - val_loss: 0.5461\n",
      "Epoch 86/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5598 - val_loss: 0.5473\n",
      "Epoch 87/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5449 - val_loss: 0.5445\n",
      "Epoch 88/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.6304 - val_loss: 0.5416\n",
      "Epoch 89/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.3779 - val_loss: 0.5524\n",
      "Epoch 90/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4453 - val_loss: 0.5413\n",
      "Epoch 91/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4313 - val_loss: 0.5551\n",
      "Epoch 92/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5015 - val_loss: 0.5549\n",
      "Epoch 93/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4308 - val_loss: 0.5488\n",
      "Epoch 94/200\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5115 - val_loss: 0.5511\n",
      "Epoch 95/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5789 - val_loss: 0.5574\n",
      "Epoch 96/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.6252 - val_loss: 0.5505\n",
      "Epoch 97/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5149 - val_loss: 0.5598\n",
      "Epoch 98/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3876 - val_loss: 0.5562\n",
      "Epoch 99/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.6250 - val_loss: 0.5575\n",
      "Epoch 100/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5129 - val_loss: 0.5638\n",
      "Epoch 101/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4812 - val_loss: 0.5646\n",
      "Epoch 102/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5259 - val_loss: 0.5533\n",
      "Epoch 103/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5534 - val_loss: 0.5769\n",
      "Epoch 104/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4219 - val_loss: 0.5548\n",
      "Epoch 105/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4820 - val_loss: 0.5697\n",
      "Epoch 106/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4693 - val_loss: 0.5694\n",
      "Epoch 107/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4540 - val_loss: 0.5622\n",
      "Epoch 108/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5195 - val_loss: 0.5644\n",
      "Epoch 109/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4739 - val_loss: 0.5626\n",
      "Epoch 110/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4610 - val_loss: 0.5833\n",
      "Epoch 111/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6430 - val_loss: 0.5756\n",
      "Epoch 112/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3937 - val_loss: 0.5776\n",
      "Epoch 113/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4740 - val_loss: 0.5695\n",
      "Epoch 114/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5270 - val_loss: 0.5867\n",
      "Epoch 115/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4397 - val_loss: 0.5859\n",
      "Epoch 116/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4893 - val_loss: 0.5797\n",
      "Epoch 117/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4956 - val_loss: 0.5770\n",
      "Epoch 118/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5345 - val_loss: 0.5900\n",
      "Epoch 119/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3686 - val_loss: 0.5847\n",
      "Epoch 120/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6556 - val_loss: 0.5886\n",
      "Epoch 121/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5093 - val_loss: 0.5893\n",
      "Epoch 122/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4949 - val_loss: 0.6057\n",
      "Epoch 123/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6356 - val_loss: 0.5949\n",
      "Epoch 124/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4293 - val_loss: 0.6044\n",
      "Epoch 125/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4424 - val_loss: 0.5965\n",
      "Epoch 126/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4567 - val_loss: 0.6127\n",
      "Epoch 127/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5490 - val_loss: 0.6119\n",
      "Epoch 128/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4591 - val_loss: 0.6068\n",
      "Epoch 129/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4086 - val_loss: 0.5944\n",
      "Epoch 130/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5641 - val_loss: 0.6024\n",
      "Epoch 131/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3782 - val_loss: 0.5956\n",
      "Epoch 132/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.5010 - val_loss: 0.6051\n",
      "Epoch 133/200\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5532 - val_loss: 0.6205\n",
      "Epoch 134/200\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4730 - val_loss: 0.6169\n",
      "Epoch 135/200\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.3932 - val_loss: 0.5986\n",
      "Epoch 136/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4551 - val_loss: 0.6099\n",
      "Epoch 137/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4303 - val_loss: 0.5998\n",
      "Epoch 138/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.3608 - val_loss: 0.6059\n",
      "Epoch 139/200\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.4325 - val_loss: 0.6286\n",
      "Epoch 140/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4692 - val_loss: 0.6142\n",
      "Epoch 141/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4622 - val_loss: 0.6177\n",
      "Epoch 142/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4328 - val_loss: 0.6159\n",
      "Epoch 143/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4652 - val_loss: 0.6191\n",
      "Epoch 144/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3708 - val_loss: 0.6118\n",
      "Epoch 145/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4756 - val_loss: 0.6195\n",
      "Epoch 146/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5271 - val_loss: 0.6026\n",
      "Epoch 147/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5473 - val_loss: 0.6206\n",
      "Epoch 148/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3895 - val_loss: 0.6178\n",
      "Epoch 149/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4990 - val_loss: 0.6167\n",
      "Epoch 150/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4848 - val_loss: 0.6152\n",
      "Epoch 151/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4919 - val_loss: 0.6269\n",
      "Epoch 152/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4284 - val_loss: 0.6313\n",
      "Epoch 153/200\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4334 - val_loss: 0.6242\n",
      "Epoch 154/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3897 - val_loss: 0.6142\n",
      "Epoch 155/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4406 - val_loss: 0.6146\n",
      "Epoch 156/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4762 - val_loss: 0.6278\n",
      "Epoch 157/200\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4142 - val_loss: 0.6158\n",
      "Epoch 158/200\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4592 - val_loss: 0.6324\n",
      "Epoch 159/200\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5482 - val_loss: 0.6230\n",
      "Epoch 160/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5478 - val_loss: 0.6348\n",
      "Epoch 161/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4110 - val_loss: 0.6184\n",
      "Epoch 162/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4393 - val_loss: 0.6289\n",
      "Epoch 163/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3707 - val_loss: 0.6326\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4400 - val_loss: 0.6321\n",
      "Epoch 165/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4940 - val_loss: 0.6339\n",
      "Epoch 166/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4069 - val_loss: 0.6272\n",
      "Epoch 167/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5840 - val_loss: 0.6351\n",
      "Epoch 168/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5046 - val_loss: 0.6227\n",
      "Epoch 169/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3726 - val_loss: 0.6394\n",
      "Epoch 170/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3979 - val_loss: 0.6388\n",
      "Epoch 171/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3777 - val_loss: 0.6301\n",
      "Epoch 172/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3572 - val_loss: 0.6289\n",
      "Epoch 173/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.3630 - val_loss: 0.6368\n",
      "Epoch 174/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4875 - val_loss: 0.6466\n",
      "Epoch 175/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3719 - val_loss: 0.6425\n",
      "Epoch 176/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5047 - val_loss: 0.6431\n",
      "Epoch 177/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4368 - val_loss: 0.6303\n",
      "Epoch 178/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4047 - val_loss: 0.6492\n",
      "Epoch 179/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4022 - val_loss: 0.6350\n",
      "Epoch 180/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4317 - val_loss: 0.6265\n",
      "Epoch 181/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4764 - val_loss: 0.6380\n",
      "Epoch 182/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3623 - val_loss: 0.6484\n",
      "Epoch 183/200\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.5214 - val_loss: 0.6535\n",
      "Epoch 184/200\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.3934 - val_loss: 0.6405\n",
      "Epoch 185/200\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.3396 - val_loss: 0.6300\n",
      "Epoch 186/200\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.4458 - val_loss: 0.6524\n",
      "Epoch 187/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4217 - val_loss: 0.6465\n",
      "Epoch 188/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4508 - val_loss: 0.6451\n",
      "Epoch 189/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3710 - val_loss: 0.6493\n",
      "Epoch 190/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.3561 - val_loss: 0.6373\n",
      "Epoch 191/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3776 - val_loss: 0.6485\n",
      "Epoch 192/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4447 - val_loss: 0.6547\n",
      "Epoch 193/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5292 - val_loss: 0.6521\n",
      "Epoch 194/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3603 - val_loss: 0.6550\n",
      "Epoch 195/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3770 - val_loss: 0.6477\n",
      "Epoch 196/200\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.3935 - val_loss: 0.6621\n",
      "Epoch 197/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4079 - val_loss: 0.6541\n",
      "Epoch 198/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4654 - val_loss: 0.6743\n",
      "Epoch 199/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4034 - val_loss: 0.6438\n",
      "Epoch 200/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3310 - val_loss: 0.6599\n"
     ]
    }
   ],
   "source": [
    "model = base_model()\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "seed(1)\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    epochs=EPOCHS, \n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "looking-fields",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.406211</td>\n",
       "      <td>0.662147</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.401180</td>\n",
       "      <td>0.654140</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.401624</td>\n",
       "      <td>0.674261</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.400649</td>\n",
       "      <td>0.643756</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.401009</td>\n",
       "      <td>0.659916</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  val_loss  epoch\n",
       "195  0.406211  0.662147    195\n",
       "196  0.401180  0.654140    196\n",
       "197  0.401624  0.674261    197\n",
       "198  0.400649  0.643756    198\n",
       "199  0.401009  0.659916    199"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "fifty-times",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "quarterly-press",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "enormous-liberia",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "lucky-liberia",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_round = np.round(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "understanding-fetish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.738562091503268"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "collect-vitamin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Data/output/REG_MODEL_ELEM\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(OUTPUT_PATH + 'REG_MODEL_ELEM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-glossary",
   "metadata": {},
   "source": [
    "### FEATURE IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "interim-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "charitable-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasRegressor(build_fn=base_model, nb_epoch=EPOCHS, \n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    validation_split=0.2)\n",
    "kfold = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "spanish-reducing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 1s 4ms/step - loss: 2.1037 - val_loss: 1.4333\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.5033\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 3.8755 - val_loss: 2.7654\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.4430\n",
      "88/88 [==============================] - 1s 4ms/step - loss: 4.6597 - val_loss: 3.0080\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.3222\n",
      "88/88 [==============================] - 1s 4ms/step - loss: 1.5299 - val_loss: 1.1852\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.2233\n",
      "88/88 [==============================] - 1s 4ms/step - loss: 2.4317 - val_loss: 1.6136\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.9418\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 2.3467 - val_loss: 1.5808\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.2551\n",
      "88/88 [==============================] - 1s 4ms/step - loss: 1.6199 - val_loss: 0.9814\n",
      "13/13 [==============================] - 0s 963us/step - loss: 0.6911\n",
      "88/88 [==============================] - 1s 4ms/step - loss: 2.6439 - val_loss: 1.9794\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.4955\n",
      "88/88 [==============================] - 1s 4ms/step - loss: 1.3525 - val_loss: 1.3950\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8193\n",
      "88/88 [==============================] - 1s 4ms/step - loss: 4.2645 - val_loss: 3.6793\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.4159\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(estimator, X_train, y_train, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "pacific-machine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -2.01 (0.86) MSE\n"
     ]
    }
   ],
   "source": [
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "automatic-lafayette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 2s 9ms/step - loss: 2.6205 - val_loss: 1.9016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1551291c9a0>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "balanced-venture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 0s 908us/step - loss: 1.9876\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9918\n",
      "123/123 [==============================] - 0s 688us/step - loss: 2.0074\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9848\n",
      "123/123 [==============================] - 0s 741us/step - loss: 1.9875\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9769\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9897\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9908\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9831\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9988\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9765\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9846\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9931\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9863\n",
      "123/123 [==============================] - 0s 687us/step - loss: 1.9932\n",
      "123/123 [==============================] - 0s 703us/step - loss: 1.9794\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9894\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 2.0036\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9783\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9803\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9899\n",
      "123/123 [==============================] - 0s 847us/step - loss: 1.9971\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9827\n",
      "123/123 [==============================] - 0s 899us/step - loss: 1.9903\n",
      "123/123 [==============================] - 0s 766us/step - loss: 1.9815\n",
      "123/123 [==============================] - 0s 715us/step - loss: 1.9963\n",
      "123/123 [==============================] - 0s 814us/step - loss: 1.9909\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9772\n",
      "123/123 [==============================] - 0s 772us/step - loss: 1.9969\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9811\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9891\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9940\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9862\n",
      "123/123 [==============================] - 0s 880us/step - loss: 1.9873\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9757\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9886\n",
      "123/123 [==============================] - 0s 826us/step - loss: 2.0035\n",
      "123/123 [==============================] - 0s 765us/step - loss: 1.9713\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9808\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9885\n",
      "123/123 [==============================] - 0s 722us/step - loss: 2.0055\n",
      "123/123 [==============================] - 0s 729us/step - loss: 1.9829\n",
      "123/123 [==============================] - 0s 825us/step - loss: 1.9904\n",
      "123/123 [==============================] - 0s 718us/step - loss: 1.9777\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9846\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9886\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9813\n",
      "123/123 [==============================] - 0s 743us/step - loss: 2.0017\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9815\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9902\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9931\n",
      "123/123 [==============================] - 0s 888us/step - loss: 1.9880\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9985\n",
      "123/123 [==============================] - 0s 712us/step - loss: 1.9809\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9900\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 2.0053\n",
      "123/123 [==============================] - 0s 777us/step - loss: 1.9848\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9831\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9870\n",
      "123/123 [==============================] - 0s 797us/step - loss: 2.0036\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9893\n",
      "123/123 [==============================] - 0s 782us/step - loss: 1.9866\n",
      "123/123 [==============================] - 0s 980us/step - loss: 1.9778\n",
      "123/123 [==============================] - 0s 775us/step - loss: 1.9864\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9985\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.9801\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 2.0013\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.9795\n",
      "123/123 [==============================] - 0s 733us/step - loss: 1.9912\n",
      "123/123 [==============================] - 0s 941us/step - loss: 1.9975\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9900\n",
      "123/123 [==============================] - 0s 736us/step - loss: 1.9965\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9847\n",
      "123/123 [==============================] - 0s 872us/step - loss: 1.9882\n",
      "123/123 [==============================] - 0s 723us/step - loss: 2.0031\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9858\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9829\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9853\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.9957\n",
      "123/123 [==============================] - 0s 723us/step - loss: 1.9864\n",
      "123/123 [==============================] - 0s 956us/step - loss: 1.9957\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.9821\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.9837\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.9930\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.9823\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 1.9950\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 1.9787\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 1.9863\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.9963\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9883\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.9895\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 1.9822\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.9897\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 2.0101\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.9807\n",
      "123/123 [==============================] - 0s 776us/step - loss: 1.9793\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0175\n",
       "                \n",
       "                    &plusmn; 0.0052\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SDG_Type_Worker_Arm\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 82.66%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0143\n",
       "                \n",
       "                    &plusmn; 0.0093\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SDG_Households_Kerosene_Gass_Light_Pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.41%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0111\n",
       "                \n",
       "                    &plusmn; 0.0051\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SDG_Type_Worker_Pro\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.27%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0072\n",
       "                \n",
       "                    &plusmn; 0.0036\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SDG_Type_Worker_Ser\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.21%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0054\n",
       "                \n",
       "                    &plusmn; 0.0083\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SDG_Type_Worker_Cra\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.96%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0048\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SDG_Type_Building_Single_Pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.90%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0025\n",
       "                \n",
       "                    &plusmn; 0.0064\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SDG_Households_Drinking_Shared_Faucet_Pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.28%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0016\n",
       "                \n",
       "                    &plusmn; 0.0014\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SDG_Type_Worker_Ele\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.52%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0009\n",
       "                \n",
       "                    &plusmn; 0.0045\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SDG_Households_Electricity_Light_Pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.95%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0007\n",
       "                \n",
       "                    &plusmn; 0.0049\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SDG_Type_Worker_Cle\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.21%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0006\n",
       "                \n",
       "                    &plusmn; 0.0091\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SDG_Building_Tenure_Type_Owned_Pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.31%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0001\n",
       "                \n",
       "                    &plusmn; 0.0029\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SDG_Type_Worker_Ski\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 95.02%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0024\n",
       "                \n",
       "                    &plusmn; 0.0049\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SDG_Households_Drinking_Owned_Faucet_Pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 90.18%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0063\n",
       "                \n",
       "                    &plusmn; 0.0030\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ELEM_POPN\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 89.69%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0068\n",
       "                \n",
       "                    &plusmn; 0.0041\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SDG_Type_Worker_Man\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 89.45%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0070\n",
       "                \n",
       "                    &plusmn; 0.0060\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SDG_Type_Worker_Pla\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 89.03%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0074\n",
       "                \n",
       "                    &plusmn; 0.0104\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SDG_less_than_54_sqft\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 88.29%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0081\n",
       "                \n",
       "                    &plusmn; 0.0036\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SDG_Type_Worker_Tec\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 88.04%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0084\n",
       "                \n",
       "                    &plusmn; 0.0043\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SDG_Households_Construction_Material_Concrete_Pct\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm = PermutationImportance(estimator, random_state=1).fit(X_train, y_train)\n",
    "eli5.show_weights(perm, feature_names = X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-cinema",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-details",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
